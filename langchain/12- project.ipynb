{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e27d803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5426db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"files/apostila.pdf\",\n",
    "    \"files/LLM.pdf\"\n",
    "]\n",
    "pages = []\n",
    "for file in files:\n",
    "    loader = PyMuPDFLoader(file)\n",
    "    pages.extend(loader.load())\n",
    "\n",
    "\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "\n",
    "recursive_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    chunk_size=chunk_size,\n",
    "    separators=[\"\\n\\n\",\"\\n\",\" \", \"\", \".\"]\n",
    ")\n",
    "documents = recursive_split.split_documents(pages)\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata[\"source\"] = doc.metadata[\"source\"].replace(\"files/\",\"\")\n",
    "    doc.metadata[\"doc_id\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e0d42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"files/chroma_retrival_db\" \n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "vectordb= Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory= directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "009b7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3966269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever= vectordb.as_retriever(search_type=\"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94ac605b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'O que é Hugging Face e como faço para acessa-lo?',\n",
       " 'result': 'Hugging Face é uma plataforma e empresa conhecida por seus modelos de aprendizado de máquina, especialmente em processamento de linguagem natural (NLP). A Hugging Face oferece uma biblioteca chamada Transformers, que permite aos desenvolvedores utilizar e ajustar modelos de linguagem pré-treinados em suas aplicações. \\n\\nPara acessar o Hugging Face, você pode visitar o site oficial em [huggingface.co](https://huggingface.co). A partir daí, você pode explorar os modelos disponíveis, usar a API da Hugging Face ou instalar a biblioteca Transformers em seu ambiente Python para trabalhar com modelos como o BERT, GPT-2, e outros. \\n\\nVocê pode instalar a biblioteca usando o comando:\\n\\n```bash\\npip install transformers\\n```\\n\\nDepois de instalada, você pode começar a usar os modelos como objetos Python em seu código.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"O que é Hugging Face e como faço para acessa-lo?\"\n",
    "\n",
    "chat_chain.invoke({\"query\":question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cf8796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Utilize o contexto forncedido para responder a pergunta ao final.\n",
    "    Se você não souber a resposta, apenas diga que não sabe e não invente uma resposta.\n",
    "    Utilize três frases no maximo, matenha a resposta concisa.\n",
    "\n",
    "    Contexto: {context}\n",
    "    Pergunta: {question}\n",
    "\n",
    "    Resposta:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c4984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever= vectordb.as_retriever(search_type=\"mmr\"),\n",
    "    chain_type_kwargs={\"prompt\":chain_prompt},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a4d8b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A apostila oferece códigos de exemplo que ajudam os usuários a começar a trabalhar com LLMs, incluindo o ChatGPT. Ela é projetada para cursos de extensão de Introdução à Programação com Python, facilitando a compreensão e a aplicação prática. Além disso, o material foi desenvolvido por um grupo de estudantes para auxiliar no aprendizado.\n"
     ]
    }
   ],
   "source": [
    "question = \"Como a apostila mostra para usar o ChatGPT?\"\n",
    "\n",
    "response = chat_chain.invoke({\"query\":question})\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e45f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'modDate': \"D:20231017132635Z00'00'\", 'file_path': 'files/LLM.pdf', 'format': 'PDF 1.4', 'author': '', 'producer': 'macOS Version 13.5 (Build 22G74) Quartz PDFContext', 'subject': '', 'source': 'LLM.pdf', 'creationDate': \"D:20231017132635Z00'00'\", 'keywords': '', 'trapped': '', 'creator': '', 'total_pages': 9, 'moddate': \"D:20231017132635Z00'00'\", 'title': '', 'doc_id': 115, 'page': 5, 'creationdate': \"D:20231017132635Z00'00'\"}, page_content='Serviços proprietários \\nComo o primeiro serviço amplamente disponível alimentado por LLM, o \\nChatGPT da OpenAI foi o catalisador explosivo que trouxe os LLMs para o \\nmainstream. O ChatGPT fornece uma interface de usuário (ou API) em que os \\nusuários podem enviar prompts para muitos \\nmodelos (GPT-3.5, GPT-4 e outros) e geralmente obter uma resposta rápida. Eles \\nestão entre os modelos de maior desempenho, treinados em conjuntos de dados'),\n",
       " Document(metadata={'creationDate': \"D:20160504100639-03'00'\", 'creator': 'Microsoft® Word 2013', 'producer': 'Microsoft® Word 2013', 'moddate': '2016-05-04T10:06:39-03:00', 'total_pages': 28, 'format': 'PDF 1.5', 'source': 'apostila.pdf', 'creationdate': '2016-05-04T10:06:39-03:00', 'modDate': \"D:20160504100639-03'00'\", 'page': 3, 'trapped': '', 'title': '', 'author': 'lucas', 'subject': '', 'file_path': 'files/apostila.pdf', 'keywords': '', 'doc_id': 13}, page_content='1 \\n \\nPREFÁCIO \\n \\nEste material foi escrito para ser utilizado em cursos de extensão de Introdução à \\nProgramação com Python, do Instituto Federal de Educação, Ciência e Tecnologia de \\nSão Paulo, câmpus São Carlos. \\nA apostila foi desenvolvida pelos integrantes do Programa de Educação Tutorial do curso \\nde Tecnologia em Análise e Desenvolvimento de Sistemas - grupo PET ADS / IFSP São \\nCarlos. O grupo iniciou suas atividades em 2011, e realiza atividades diversas envolvendo'),\n",
       " Document(metadata={'moddate': \"D:20231017132635Z00'00'\", 'page': 7, 'creationdate': \"D:20231017132635Z00'00'\", 'total_pages': 9, 'title': '', 'trapped': '', 'file_path': 'files/LLM.pdf', 'creationDate': \"D:20231017132635Z00'00'\", 'creator': '', 'modDate': \"D:20231017132635Z00'00'\", 'producer': 'macOS Version 13.5 (Build 22G74) Quartz PDFContext', 'author': '', 'format': 'PDF 1.4', 'subject': '', 'keywords': '', 'source': 'LLM.pdf', 'doc_id': 127}, page_content='código de exemplo que podem ajudar você a começar a trabalhar com LLMs \\nimediatamente.'),\n",
       " Document(metadata={'moddate': \"D:20231017132635Z00'00'\", 'creator': '', 'doc_id': 66, 'format': 'PDF 1.4', 'author': '', 'subject': '', 'total_pages': 9, 'creationDate': \"D:20231017132635Z00'00'\", 'source': 'LLM.pdf', 'keywords': '', 'producer': 'macOS Version 13.5 (Build 22G74) Quartz PDFContext', 'page': 6, 'title': '', 'creationdate': \"D:20231017132635Z00'00'\", 'modDate': \"D:20231017132635Z00'00'\", 'trapped': '', 'file_path': 'files/LLM.pdf'}, page_content='Um guia compacto sobre grandes modelos de \\n(\\n)\\n7 \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nAtualmente, requer um pouco mais de esforço para pegar um modelo de código \\naberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente \\npara torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos \\nmelhorias em frameworks de código aberto como o MLflow para tornar muito \\nfácil para alguém com um pouco de experiência em Python pegar qualquer \\nmodelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas \\nvezes, você pode encontrar um modelo de código aberto que resolve seu \\nproblema específico e que é várias ordens de grandeza menor que o ChatGPT, \\npermitindo que você traga o modelo para seu ambiente e hospede-o você \\nmesmo. Isso significa que você pode manter os dados sob seu controle para \\npreocupações com privacidade e governança, além de gerenciar seus custos. \\nOutra grande vantagem de usar modelos de código aberto é a capacidade de')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"source_documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ecb70",
   "metadata": {},
   "source": [
    "### Como debugar a cadeia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b01a1168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"O que é Hugging Face e como faço para acessá-lo?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"O que é Hugging Face e como faço para acessá-lo?\",\n",
      "  \"context\": \"modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas \\nvezes, você pode encontrar um modelo de código aberto que resolve seu \\nproblema específico e que é várias ordens de grandeza menor que o ChatGPT, \\npermitindo que você traga o modelo para seu ambiente e hospede-o você \\nmesmo. Isso significa que você pode manter os dados sob seu controle para \\npreocupações com privacidade e governança, além de gerenciar seus custos.\\n\\nSobre a Databricks \\nA Databricks é a empresa de dados e IA. Mais de 9.000 \\norganizações em todo o mundo, incluindo a Comcast, Condé Nast \\ne mais de 50% da Fortune 500, contam com a Plataforma \\nDatabricks Lakehouse para unificar seus dados, análises e IA. A \\nDatabricks tem sede em São Francisco, com escritórios em todo o \\nmundo. \\nFundada pelos criadores originais do Apache Spark™, Delta Lake e \\nMLflow, a Databricks tem como missão ajudar as equipes de dados a \\nresolver os problemas mais difíceis do mundo. Para saber mais, siga a \\nDatabricks no Twitter, LinkedIn e Facebook. \\n \\n \\n \\n \\n            EXPERIMENTE GRÁTIS  \\n \\n \\nEntre em contato conosco para ver uma demonstração: \\ndatabricks.com/contact \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n© Databricks 2023. Todos os direitos reservados. Apache, Apache Spark, Spark e o logotipo Spark são marcas registradas da Apache Software Foundation. Política de privacidade | Termos de uso\\n\\nbase sólida de dados quanto as ferramentas integradas para permitir que você \\nuse e ajuste os LLMs no seu domínio.\\n\\nReforçando, este é um material introdutório. Tem muito mais para aprender em Python: \\norientação a objetos, programação funcional, metaprogramação, interface gráfica, \\nexpressões regulares, threads, tratamento de exceções, funções anônimas, geradores, \\ndesenvolvimento web, aplicativos móveis, entre outras.  \\nBem-vindo ao mundo Python! \\n \\n \\n \\nProf. Dr. João Luiz Franco \\nTutor do grupo PET - ADS / São Carlos\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: \\n    Utilize o contexto forncedido para responder a pergunta ao final.\\n    Se você não souber a resposta, apenas diga que não sabe e não invente uma resposta.\\n    Utilize três frases no maximo, matenha a resposta concisa.\\n\\n    Contexto: modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas \\nvezes, você pode encontrar um modelo de código aberto que resolve seu \\nproblema específico e que é várias ordens de grandeza menor que o ChatGPT, \\npermitindo que você traga o modelo para seu ambiente e hospede-o você \\nmesmo. Isso significa que você pode manter os dados sob seu controle para \\npreocupações com privacidade e governança, além de gerenciar seus custos.\\n\\nSobre a Databricks \\nA Databricks é a empresa de dados e IA. Mais de 9.000 \\norganizações em todo o mundo, incluindo a Comcast, Condé Nast \\ne mais de 50% da Fortune 500, contam com a Plataforma \\nDatabricks Lakehouse para unificar seus dados, análises e IA. A \\nDatabricks tem sede em São Francisco, com escritórios em todo o \\nmundo. \\nFundada pelos criadores originais do Apache Spark™, Delta Lake e \\nMLflow, a Databricks tem como missão ajudar as equipes de dados a \\nresolver os problemas mais difíceis do mundo. Para saber mais, siga a \\nDatabricks no Twitter, LinkedIn e Facebook. \\n \\n \\n \\n \\n            EXPERIMENTE GRÁTIS  \\n \\n \\nEntre em contato conosco para ver uma demonstração: \\ndatabricks.com/contact \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n© Databricks 2023. Todos os direitos reservados. Apache, Apache Spark, Spark e o logotipo Spark são marcas registradas da Apache Software Foundation. Política de privacidade | Termos de uso\\n\\nbase sólida de dados quanto as ferramentas integradas para permitir que você \\nuse e ajuste os LLMs no seu domínio.\\n\\nReforçando, este é um material introdutório. Tem muito mais para aprender em Python: \\norientação a objetos, programação funcional, metaprogramação, interface gráfica, \\nexpressões regulares, threads, tratamento de exceções, funções anônimas, geradores, \\ndesenvolvimento web, aplicativos móveis, entre outras.  \\nBem-vindo ao mundo Python! \\n \\n \\n \\nProf. Dr. João Luiz Franco \\nTutor do grupo PET - ADS / São Carlos\\n    Pergunta: O que é Hugging Face e como faço para acessá-lo?\\n\\n    Resposta:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [2.04s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Hugging Face é uma plataforma que oferece modelos de processamento de linguagem natural, como transformadores, que podem ser usados como objetos Python. Você pode acessar os modelos abertos por meio da biblioteca Hugging Face Transformers, que pode ser instalada via pip. Após instalar, você pode carregar e usar os modelos diretamente em seu ambiente de programação Python.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Hugging Face é uma plataforma que oferece modelos de processamento de linguagem natural, como transformadores, que podem ser usados como objetos Python. Você pode acessar os modelos abertos por meio da biblioteca Hugging Face Transformers, que pode ser instalada via pip. Após instalar, você pode carregar e usar os modelos diretamente em seu ambiente de programação Python.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 69,\n",
      "                \"prompt_tokens\": 545,\n",
      "                \"total_tokens\": 614,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"id\": \"chatcmpl-C0d7pKezjwt0ZxUjO9fWr168DI2Q0\",\n",
      "              \"service_tier\": \"default\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--c2f116bd-31d9-43c1-a175-86e4c693f44f-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 545,\n",
      "              \"output_tokens\": 69,\n",
      "              \"total_tokens\": 614,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 69,\n",
      "      \"prompt_tokens\": 545,\n",
      "      \"total_tokens\": 614,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "    \"id\": \"chatcmpl-C0d7pKezjwt0ZxUjO9fWr168DI2Q0\",\n",
      "    \"service_tier\": \"default\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [2.04s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Hugging Face é uma plataforma que oferece modelos de processamento de linguagem natural, como transformadores, que podem ser usados como objetos Python. Você pode acessar os modelos abertos por meio da biblioteca Hugging Face Transformers, que pode ser instalada via pip. Após instalar, você pode carregar e usar os modelos diretamente em seu ambiente de programação Python.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [2.04s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Hugging Face é uma plataforma que oferece modelos de processamento de linguagem natural, como transformadores, que podem ser usados como objetos Python. Você pode acessar os modelos abertos por meio da biblioteca Hugging Face Transformers, que pode ser instalada via pip. Após instalar, você pode carregar e usar os modelos diretamente em seu ambiente de programação Python.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [2.82s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc139f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever= vectordb.as_retriever(search_type=\"mmr\"),\n",
    "    chain_type=\"refine\"\n",
    ")\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "print(response[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
